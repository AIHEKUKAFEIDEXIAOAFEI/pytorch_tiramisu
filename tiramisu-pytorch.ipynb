{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "( 0 , 0 ,.,.) = \n",
      "  1  1\n",
      "  1  1\n",
      "\n",
      "( 0 , 1 ,.,.) = \n",
      "  1  1\n",
      "  1  1\n",
      "\n",
      "( 0 , 2 ,.,.) = \n",
      "  1  1\n",
      "  1  1\n",
      "    ... \n",
      "\n",
      "( 0 , 8 ,.,.) = \n",
      "  1  1\n",
      "  1  1\n",
      "\n",
      "( 0 , 9 ,.,.) = \n",
      "  1  1\n",
      "  1  1\n",
      "\n",
      "( 0 ,10 ,.,.) = \n",
      "  1  1\n",
      "  1  1\n",
      "      ⋮  \n",
      "\n",
      "( 1 , 0 ,.,.) = \n",
      "  1  1\n",
      "  1  1\n",
      "\n",
      "( 1 , 1 ,.,.) = \n",
      "  1  1\n",
      "  1  1\n",
      "\n",
      "( 1 , 2 ,.,.) = \n",
      "  1  1\n",
      "  1  1\n",
      "    ... \n",
      "\n",
      "( 1 , 8 ,.,.) = \n",
      "  1  1\n",
      "  1  1\n",
      "\n",
      "( 1 , 9 ,.,.) = \n",
      "  1  1\n",
      "  1  1\n",
      "\n",
      "( 1 ,10 ,.,.) = \n",
      "  1  1\n",
      "  1  1\n",
      "      ⋮  \n",
      "\n",
      "( 2 , 0 ,.,.) = \n",
      "  1  1\n",
      "  1  1\n",
      "\n",
      "( 2 , 1 ,.,.) = \n",
      "  1  1\n",
      "  1  1\n",
      "\n",
      "( 2 , 2 ,.,.) = \n",
      "  1  1\n",
      "  1  1\n",
      "    ... \n",
      "\n",
      "( 2 , 8 ,.,.) = \n",
      "  1  1\n",
      "  1  1\n",
      "\n",
      "( 2 , 9 ,.,.) = \n",
      "  1  1\n",
      "  1  1\n",
      "\n",
      "( 2 ,10 ,.,.) = \n",
      "  1  1\n",
      "  1  1\n",
      "...     \n",
      "      ⋮  \n",
      "\n",
      "(373, 0 ,.,.) = \n",
      "  1  1\n",
      "  1  1\n",
      "\n",
      "(373, 1 ,.,.) = \n",
      "  1  1\n",
      "  1  1\n",
      "\n",
      "(373, 2 ,.,.) = \n",
      "  1  1\n",
      "  1  1\n",
      "    ... \n",
      "\n",
      "(373, 8 ,.,.) = \n",
      "  1  1\n",
      "  1  1\n",
      "\n",
      "(373, 9 ,.,.) = \n",
      "  1  1\n",
      "  1  1\n",
      "\n",
      "(373,10 ,.,.) = \n",
      "  1  1\n",
      "  1  1\n",
      "      ⋮  \n",
      "\n",
      "(374, 0 ,.,.) = \n",
      "  1  1\n",
      "  1  1\n",
      "\n",
      "(374, 1 ,.,.) = \n",
      "  1  1\n",
      "  1  1\n",
      "\n",
      "(374, 2 ,.,.) = \n",
      "  1  1\n",
      "  1  1\n",
      "    ... \n",
      "\n",
      "(374, 8 ,.,.) = \n",
      "  1  1\n",
      "  1  1\n",
      "\n",
      "(374, 9 ,.,.) = \n",
      "  1  1\n",
      "  1  1\n",
      "\n",
      "(374,10 ,.,.) = \n",
      "  1  1\n",
      "  1  1\n",
      "      ⋮  \n",
      "\n",
      "(375, 0 ,.,.) = \n",
      "  1  1\n",
      "  1  1\n",
      "\n",
      "(375, 1 ,.,.) = \n",
      "  1  1\n",
      "  1  1\n",
      "\n",
      "(375, 2 ,.,.) = \n",
      "  1  1\n",
      "  1  1\n",
      "    ... \n",
      "\n",
      "(375, 8 ,.,.) = \n",
      "  1  1\n",
      "  1  1\n",
      "\n",
      "(375, 9 ,.,.) = \n",
      "  1  1\n",
      "  1  1\n",
      "\n",
      "(375,10 ,.,.) = \n",
      "  1  1\n",
      "  1  1\n",
      "[torch.FloatTensor of size 376x11x2x2]\n",
      "\n",
      "\n",
      "    1     1     1  ...      1     1     1\n",
      "    1     1     1  ...      1     1     1\n",
      "    1     1     1  ...      1     1     1\n",
      "       ...          ⋱          ...       \n",
      "    1     1     1  ...      1     1     1\n",
      "    1     1     1  ...      1     1     1\n",
      "    1     1     1  ...      1     1     1\n",
      "[torch.FloatTensor of size 1504x11]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1504, 11])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# BatchSize, ChannelsInFinalConvLayer, ImageWidth?, ImageHeight? \n",
    "t = torch.ones((376, 11, 2, 2))\n",
    "print(t)\n",
    "t.size()\n",
    "t = t.view(376*2*2, 11)\n",
    "print(t)\n",
    "t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "import imp\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import utils.training as train_utils; imp.reload(train_utils)\n",
    "import utils.plot as plot_utils; imp.reload(plot_utils)\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH='data/'\n",
    "RESULTS_PATH='results/'\n",
    "WEIGHTS_PATH='models/'\n",
    "PROJECT_NAME='tiramisu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FirstConvLayer**\n",
    "\n",
    "* 3x3 Conv2D (pad=, stride=, in_chans=3, out_chans=48)\n",
    "\n",
    "**DenseLayer**\n",
    "\n",
    "* BatchNorm\n",
    "* ReLU\n",
    "* 3x3 Conv2d (pad=, stride=, in_chans=, out_chans=) - \"no resolution loss\" - padding included\n",
    "* Dropout (.2)\n",
    "\n",
    "**DenseBlock**\n",
    "\n",
    "* Input = FirstConvLayer, TransitionDown, or TransitionUp\n",
    "* Loop to create L DenseLayers (L=n_layers)\n",
    "* On TransitionDown we Concat(Input, FinalDenseLayerActivation)\n",
    "* On TransitionUp we do not Concat with input, instead pass FinalDenseLayerActivation to TransitionUp block\n",
    "\n",
    "**TransitionDown**\n",
    "\n",
    "* BatchNorm\n",
    "* ReLU\n",
    "* 1x1 Conv2D (pad=, stride=, in_chans=, out_chans=)\n",
    "* Dropout (0.2)\n",
    "* 2x2 MaxPooling\n",
    "\n",
    "**Bottleneck**\n",
    "\n",
    "* DenseBlock (15 layers)\n",
    "\n",
    "**TransitionUp**\n",
    "\n",
    "* 3x3 Transposed Convolution (pad=, stride=2, in_chans=, out_chans=)\n",
    "* Concat(PreviousDenseBlock, SkipConnection) - from cooresponding DenseBlock on transition down\n",
    "\n",
    "**FinalBlock**\n",
    "\n",
    "* 1x1 Conv2d (pad=, stride=, in_chans=256, out_chans=n_classes)\n",
    "* Softmax\n",
    "\n",
    "**FCDenseNet103 Architecture**\n",
    "\n",
    "* input (in_chans=3 for RGB)\n",
    "* 3x3 ConvLayer (out_chans=48)\n",
    "* DB (4 layers) + TD\n",
    "* DB (5 layers) + TD\n",
    "* DB (7 layers) + TD\n",
    "* DB (10 layers) + TD\n",
    "* DB (12 layers) + TD\n",
    "* Bottleneck (15 layers)\n",
    "* TU + DB (12 layers)\n",
    "* TU + DB (10 layers)\n",
    "* TU + DB (7 layers)\n",
    "* TU + DB (5 layers)\n",
    "* TU + DB (4 layers)\n",
    "* 1x1 ConvLayer (out_chans=n_classes) n_classes=11 for CamVid\n",
    "* Softmax\n",
    "\n",
    "**FCDenseNet56**\n",
    "\n",
    "GrowthRate (k) = 12\n",
    "4 layers per dense block\n",
    "1 Conv Layer\n",
    "5 DenseBlocks Downsample (20 layers)\n",
    "5 TransitionDown\n",
    "4 Bottleneck layers\n",
    "5 Dense Blocks Upsample (20 layers)\n",
    "5 TransitionUp\n",
    "1 Conv Layer\n",
    "1 Softmax layer (doesn't count)\n",
    "56 Total layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DenseLayer(nn.Module):\n",
    "    def __init__(self, in_channels, growth_rate):\n",
    "        super(DenseLayer, self).__init__()\n",
    "        self.out_channels = in_channels + growth_rate\n",
    "        self.add_module('norm', nn.BatchNorm2d(num_features=in_channels))\n",
    "        self.add_module('relu', nn.ReLU(inplace=True))\n",
    "        \n",
    "        #author's impl - lasange 'same' pads with half filter size (rounded down) on \"both\" sides\n",
    "        self.add_module('conv', nn.Conv2d(in_channels=in_channels, \n",
    "                out_channels=self.out_channels, kernel_size=3, stride=1, \n",
    "                  padding=3//2, bias=True))\n",
    "        \n",
    "        self.add_module('drop', nn.Dropout2d(0.2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        return torch.cat([x, new_features], 1) # 1 = channel axis\n",
    "    \n",
    "\n",
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, in_channels, growth_rate, n_layers):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        \n",
    "        n_channels = in_channels\n",
    "        for i in range(n_layers):\n",
    "            layer = DenseLayer(n_channels, growth_rate)\n",
    "            self.add_module('denselayer%d' % (i + 1), layer)\n",
    "            n_channels += growth_rate\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.features(x)\n",
    "\n",
    "    \n",
    "class TransitionDown(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(TransitionDown, self).__init__()\n",
    "        self.add_module('norm', nn.BatchNorm2d(num_features=in_channels))\n",
    "        self.add_module('relu', nn.ReLU(inplace=True))\n",
    "        #what is out_channels?\n",
    "        self.add_module('conv', nn.Conv2d(in_channels=in_channels, out_channels=in_channels,\n",
    "                                          kernel_size=1, stride=1, padding=0, bias=True))\n",
    "        self.add_module('drop', nn.Dropout2d(0.2))\n",
    "        self.add_module('maxpool', nn.MaxPool2d(2))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.forward(x)\n",
    "    \n",
    "class TransitionUp(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(TransitionUp, self).__init__()\n",
    "        self.add_module('transpose', nn.ConvTranspose2d(in_channels=in_channels, \n",
    "                           out_channels=out_channels, kernel_size=3, stride=2, \n",
    "                            padding=0, bias=True))\n",
    "        \n",
    "    def forward(self, x, skip_connection):\n",
    "        out = self.forward(x)\n",
    "        #l = ConcatLayer([l, skip_connection], cropping=[None, None, 'center', 'center'])\n",
    "        return torch.cat([out, skip_connection])\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self, in_channels, growth_rate, n_layers):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.add_module('bottleneck', DenseBlock(in_channels, growth_rate, n_layers))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.forward(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class FCDenseNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, n_blocks=5, layers_per_block=5, growth_rate=16, \n",
    "                 out_chans_first_conv=48, n_classes=11):\n",
    "        super(FCDenseNet, self).__init__()\n",
    "        self.n_blocks = n_blocks\n",
    "        self.n_channels = 0\n",
    "        \n",
    "        #####################\n",
    "        # First Convolution #\n",
    "        #####################\n",
    "        #W=HeUniform(gain='relu') ??\n",
    "        #pad='same'\n",
    "        self.firstConv = nn.Conv2d(in_channels=in_channels, \n",
    "                  out_channels=out_chans_first_conv, kernel_size=3, \n",
    "                  stride=1, padding=in_channels//2, bias=False)\n",
    "        self.n_channels += out_chans_first_conv\n",
    "        \n",
    "        #####################\n",
    "        # Downsampling path #\n",
    "        #####################\n",
    "        \n",
    "        skipConnectChannels = []\n",
    "        self.denseBlocksDown = []\n",
    "        self.transDownBlocks = []\n",
    "        for i in range(n_blocks):\n",
    "            db = DenseBlock(self.n_channels, growth_rate, layers_per_block)\n",
    "            self.add_module(\"DBDown%d\" % (i+1), db)\n",
    "            self.denseBlocksDown.append(db)\n",
    "            self.n_channels += (growth_rate*layers_per_block)\n",
    "            skipConnectChannels.insert(0, self.n_channels)\n",
    "            \n",
    "            td = TransitionDown(self.n_channels)\n",
    "            self.transDownBlocks.append(td)\n",
    "            self.add_module(\"TD%d\" % (i+1), td)\n",
    "            \n",
    "        #####################\n",
    "        #     Bottleneck    #\n",
    "        #####################\n",
    "        \n",
    "        self.bottleneck = Bottleneck(self.n_channels, growth_rate, layers_per_block)\n",
    "        prev_block_channels = growth_rate*layers_per_block\n",
    "        self.n_channels += prev_block_channels \n",
    "        \n",
    "        #######################\n",
    "        #   Upsampling path   #\n",
    "        #######################\n",
    "\n",
    "        self.transUpBlocks = []\n",
    "        self.denseBlocksUp = [] \n",
    "        for i in range(n_blocks):\n",
    "            tu = TransitionUp(self.n_channels, prev_block_channels + skipConnectChannels[i])\n",
    "            self.transUpBlocks.append(td)\n",
    "            self.add_module(\"TU%d\" % (i+1), tu)\n",
    "            \n",
    "            self.n_channels = prev_block_channels + skipConnectChannels[i]\n",
    "\n",
    "            db = DenseBlock(self.n_channels, growth_rate, layers_per_block)\n",
    "            self.denseBlocksUp.append(db)\n",
    "            self.add_module(\"DBUp%d\" % (i+1), db)\n",
    "\n",
    "            prev_block_channels = growth_rate*layers_per_block\n",
    "            self.n_channels += prev_block_channels\n",
    "            \n",
    "        #####################\n",
    "        #      Softmax      #\n",
    "        #####################\n",
    "        \n",
    "        self.finalConv = nn.Conv2d(in_channels=self.n_channels, out_channels=n_classes,\n",
    "                       kernel_size=1, stride=1, padding=0, bias=True)\n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.firstConv(x)\n",
    "        skip_connections = []\n",
    "        for i in range(self.n_blocks):\n",
    "            out = self.denseBlocksDown[i](out)\n",
    "            skip_connections.insert(0, out)\n",
    "            out = self.transDownBlocks[i](out)\n",
    "            \n",
    "        out = self.bottleneck(out)\n",
    "        \n",
    "        for i in range(self.n_blocks):\n",
    "            out = self.transDownBlocks[i](out, skip_connections[i]) \n",
    "            out = self.denseBlocksUp[i](out)\n",
    "        \n",
    "        out = self.finalConv(out)\n",
    "        # Reshape\n",
    "        batch_size = out.size()[0]\n",
    "        rows = out.size()[2]\n",
    "        cols = out.size()[3]\n",
    "        out = out.view(batch_size*row*cols, n_classes)\n",
    "        \n",
    "        out = self.softmax(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = FCDenseNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCDenseNet (\n",
      "  (firstConv): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (DBDown1): DenseBlock (\n",
      "    (denselayer1): DenseLayer (\n",
      "      (norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer2): DenseLayer (\n",
      "      (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(64, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer3): DenseLayer (\n",
      "      (norm): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(80, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer4): DenseLayer (\n",
      "      (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(96, 112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer5): DenseLayer (\n",
      "      (norm): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(112, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "  )\n",
      "  (TD1): TransitionDown (\n",
      "    (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu): ReLU (inplace)\n",
      "    (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (drop): Dropout2d (p=0.2)\n",
      "    (maxpool): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  )\n",
      "  (DBDown2): DenseBlock (\n",
      "    (denselayer1): DenseLayer (\n",
      "      (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(128, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer2): DenseLayer (\n",
      "      (norm): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(144, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer3): DenseLayer (\n",
      "      (norm): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(160, 176, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer4): DenseLayer (\n",
      "      (norm): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(176, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer5): DenseLayer (\n",
      "      (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(192, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "  )\n",
      "  (TD2): TransitionDown (\n",
      "    (norm): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu): ReLU (inplace)\n",
      "    (conv): Conv2d(208, 208, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (drop): Dropout2d (p=0.2)\n",
      "    (maxpool): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  )\n",
      "  (DBDown3): DenseBlock (\n",
      "    (denselayer1): DenseLayer (\n",
      "      (norm): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(208, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer2): DenseLayer (\n",
      "      (norm): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(224, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer3): DenseLayer (\n",
      "      (norm): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(240, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer4): DenseLayer (\n",
      "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(256, 272, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer5): DenseLayer (\n",
      "      (norm): BatchNorm2d(272, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(272, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "  )\n",
      "  (TD3): TransitionDown (\n",
      "    (norm): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu): ReLU (inplace)\n",
      "    (conv): Conv2d(288, 288, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (drop): Dropout2d (p=0.2)\n",
      "    (maxpool): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  )\n",
      "  (DBDown4): DenseBlock (\n",
      "    (denselayer1): DenseLayer (\n",
      "      (norm): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(288, 304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer2): DenseLayer (\n",
      "      (norm): BatchNorm2d(304, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(304, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer3): DenseLayer (\n",
      "      (norm): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(320, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer4): DenseLayer (\n",
      "      (norm): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(336, 352, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer5): DenseLayer (\n",
      "      (norm): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(352, 368, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "  )\n",
      "  (TD4): TransitionDown (\n",
      "    (norm): BatchNorm2d(368, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu): ReLU (inplace)\n",
      "    (conv): Conv2d(368, 368, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (drop): Dropout2d (p=0.2)\n",
      "    (maxpool): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  )\n",
      "  (DBDown5): DenseBlock (\n",
      "    (denselayer1): DenseLayer (\n",
      "      (norm): BatchNorm2d(368, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(368, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer2): DenseLayer (\n",
      "      (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(384, 400, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer3): DenseLayer (\n",
      "      (norm): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(400, 416, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer4): DenseLayer (\n",
      "      (norm): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(416, 432, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer5): DenseLayer (\n",
      "      (norm): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(432, 448, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "  )\n",
      "  (TD5): TransitionDown (\n",
      "    (norm): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu): ReLU (inplace)\n",
      "    (conv): Conv2d(448, 448, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (drop): Dropout2d (p=0.2)\n",
      "    (maxpool): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  )\n",
      "  (bottleneck): Bottleneck (\n",
      "    (bottleneck): DenseBlock (\n",
      "      (denselayer1): DenseLayer (\n",
      "        (norm): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu): ReLU (inplace)\n",
      "        (conv): Conv2d(448, 464, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (drop): Dropout2d (p=0.2)\n",
      "      )\n",
      "      (denselayer2): DenseLayer (\n",
      "        (norm): BatchNorm2d(464, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu): ReLU (inplace)\n",
      "        (conv): Conv2d(464, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (drop): Dropout2d (p=0.2)\n",
      "      )\n",
      "      (denselayer3): DenseLayer (\n",
      "        (norm): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu): ReLU (inplace)\n",
      "        (conv): Conv2d(480, 496, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (drop): Dropout2d (p=0.2)\n",
      "      )\n",
      "      (denselayer4): DenseLayer (\n",
      "        (norm): BatchNorm2d(496, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu): ReLU (inplace)\n",
      "        (conv): Conv2d(496, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (drop): Dropout2d (p=0.2)\n",
      "      )\n",
      "      (denselayer5): DenseLayer (\n",
      "        (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu): ReLU (inplace)\n",
      "        (conv): Conv2d(512, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (drop): Dropout2d (p=0.2)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (TU1): TransitionUp (\n",
      "    (transpose): ConvTranspose2d(528, 528, kernel_size=(3, 3), stride=(2, 2))\n",
      "  )\n",
      "  (DBUp1): DenseBlock (\n",
      "    (denselayer1): DenseLayer (\n",
      "      (norm): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(528, 544, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer2): DenseLayer (\n",
      "      (norm): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(544, 560, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer3): DenseLayer (\n",
      "      (norm): BatchNorm2d(560, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(560, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer4): DenseLayer (\n",
      "      (norm): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(576, 592, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer5): DenseLayer (\n",
      "      (norm): BatchNorm2d(592, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(592, 608, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "  )\n",
      "  (TU2): TransitionUp (\n",
      "    (transpose): ConvTranspose2d(608, 448, kernel_size=(3, 3), stride=(2, 2))\n",
      "  )\n",
      "  (DBUp2): DenseBlock (\n",
      "    (denselayer1): DenseLayer (\n",
      "      (norm): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(448, 464, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer2): DenseLayer (\n",
      "      (norm): BatchNorm2d(464, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(464, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer3): DenseLayer (\n",
      "      (norm): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(480, 496, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer4): DenseLayer (\n",
      "      (norm): BatchNorm2d(496, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(496, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer5): DenseLayer (\n",
      "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(512, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "  )\n",
      "  (TU3): TransitionUp (\n",
      "    (transpose): ConvTranspose2d(528, 368, kernel_size=(3, 3), stride=(2, 2))\n",
      "  )\n",
      "  (DBUp3): DenseBlock (\n",
      "    (denselayer1): DenseLayer (\n",
      "      (norm): BatchNorm2d(368, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(368, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer2): DenseLayer (\n",
      "      (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(384, 400, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer3): DenseLayer (\n",
      "      (norm): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(400, 416, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer4): DenseLayer (\n",
      "      (norm): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(416, 432, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer5): DenseLayer (\n",
      "      (norm): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(432, 448, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "  )\n",
      "  (TU4): TransitionUp (\n",
      "    (transpose): ConvTranspose2d(448, 288, kernel_size=(3, 3), stride=(2, 2))\n",
      "  )\n",
      "  (DBUp4): DenseBlock (\n",
      "    (denselayer1): DenseLayer (\n",
      "      (norm): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(288, 304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer2): DenseLayer (\n",
      "      (norm): BatchNorm2d(304, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(304, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer3): DenseLayer (\n",
      "      (norm): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(320, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer4): DenseLayer (\n",
      "      (norm): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(336, 352, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer5): DenseLayer (\n",
      "      (norm): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(352, 368, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "  )\n",
      "  (TU5): TransitionUp (\n",
      "    (transpose): ConvTranspose2d(368, 208, kernel_size=(3, 3), stride=(2, 2))\n",
      "  )\n",
      "  (DBUp5): DenseBlock (\n",
      "    (denselayer1): DenseLayer (\n",
      "      (norm): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(208, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer2): DenseLayer (\n",
      "      (norm): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(224, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer3): DenseLayer (\n",
      "      (norm): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(240, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer4): DenseLayer (\n",
      "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(256, 272, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer5): DenseLayer (\n",
      "      (norm): BatchNorm2d(272, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(272, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "  )\n",
      "  (finalConv): Conv2d(288, 11, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (softmax): Softmax ()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE=64\n",
    "CIFAR10_PATH=DATA_PATH+'cifar10/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.manual_seed(1)\n",
    "\n",
    "normMean = [0.49139968, 0.48215827, 0.44653124]\n",
    "normStd = [0.24703233, 0.24348505, 0.26158768]\n",
    "normTransform = transforms.Normalize(normMean, normStd)\n",
    "\n",
    "trainTransform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normTransform\n",
    "])\n",
    "testTransform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normTransform\n",
    "])\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True}\n",
    "trainLoader = DataLoader(\n",
    "    dset.CIFAR10(root=CIFAR10_PATH, train=True, download=True,\n",
    "                 transform=trainTransform),\n",
    "    batch_size=BATCH_SIZE, shuffle=True, **kwargs)\n",
    "testLoader = DataLoader(\n",
    "    dset.CIFAR10(root=CIFAR10_PATH, train=False, download=True,\n",
    "                 transform=testTransform),\n",
    "    batch_size=BATCH_SIZE, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Hyperparameters**\n",
    "\n",
    "* WeightInitialization = HeUniform\n",
    "* Optimizer = RMSProp\n",
    "* LR = .001 with exponential decay of 0.995 after each epoch\n",
    "* Data Augmentation = Random Crops, Vertical Flips\n",
    "* ValidationSet with early stopping based on IoU or MeanAccuracy with patience of 100 (50 during finetuning)\n",
    "* WeightDecay = .0001\n",
    "* Finetune with full-size images, LR = .0001\n",
    "* Dropout = 0.2\n",
    "* BatchNorm \"we use current batch stats at training, validation, and test time\"\n",
    "\n",
    "**CamVid**\n",
    "\n",
    "* TrainingSet = 367 frames\n",
    "* ValidationSet = 101 frames\n",
    "* TestSet = 233 frames\n",
    "* Images of resolution 360x480\n",
    "* Images \"Cropped\" to 224x224 for training --- center crop?\n",
    "* FullRes images used for finetuning\n",
    "* NumberOfClasses = 11 (output)\n",
    "* BatchSize = 3\n",
    "\n",
    "**FCDenseNet103**\n",
    "\n",
    "* GrowthRate = 16 (k, number of filters to each denselayer adds to the ever-growing concatenated output)\n",
    "* No pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  + Number of params: 1059298\n",
      "Training new model from scratch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train - Loss: 1.370707\tError: 43.750000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 1/1 [01:12<00:00, 72.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test - Loss: 1.3404, Error: 4590/10000 (46%)\n",
      "Time 1m 12s\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "existing_weights_fpath=None\n",
    "nEpochs=1\n",
    "\n",
    "net = DenseNet(growthRate=12, depth=40, reduction=1.0, \n",
    "                   bottleneck=False, nClasses=10)\n",
    "net = net.cuda()\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=1e-1,\n",
    "                momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "print('  + Number of params: {}'.format(\n",
    "    sum([p.data.nelement() for p in net.parameters()])))\n",
    "\n",
    "if existing_weights_fpath:\n",
    "    startEpoch = train_utils.load_weights(net, existing_weights_fpath)\n",
    "    endEpoch = startEpoch + nEpochs\n",
    "    print ('Resume training at epoch: {}'.format(startEpoch))\n",
    "    if os.path.exists(RESULTS_PATH+'train.csv'): #assume test.csv exists\n",
    "        append_write = 'a' # append if already exists\n",
    "    else:\n",
    "        append_write = 'w' # make a new file if not\n",
    "    trainF = open(os.path.join(RESULTS_PATH, 'train.csv'), append_write)\n",
    "    testF = open(os.path.join(RESULTS_PATH, 'test.csv'), append_write)\n",
    "else:\n",
    "    print (\"Training new model from scratch\")\n",
    "    startEpoch = 1\n",
    "    endEpoch = nEpochs\n",
    "    trainF = open(os.path.join(RESULTS_PATH, 'train.csv'), 'w')\n",
    "    testF = open(os.path.join(RESULTS_PATH, 'test.csv'), 'w')\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(startEpoch, endEpoch+1)):\n",
    "    since = time.time()\n",
    "    train_utils.adjust_opt(\"sgd\", optimizer, epoch)\n",
    "    train_utils.train(epoch, net, trainLoader, optimizer, trainF)\n",
    "    train_utils.test(epoch, net, testLoader, optimizer, testF)\n",
    "    time_elapsed = time.time() - since  \n",
    "    print('Time {:.0f}m {:.0f}s\\n'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    if epoch != 1:\n",
    "        os.system('./utils/plot.py {} &'.format(RESULTS_PATH))\n",
    "\n",
    "trainF.close()\n",
    "testF.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "120px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
